# Day 5: Multiple Linear Regression & Gradient Descent ðŸ“‰

## Topics Covered:
1. **Multiple Linear Regression:**
   - Moving beyond simple `y = mx + c`.
   - Predicting outcomes based on multiple variables (e.g., House Price based on Size, Location, and Age).
2. **Gradient Descent:**
   - The optimization algorithm that powers Machine Learning.
   - Learned how the model iteratively reduces error (Cost Function) to find the best-fit line.
   - *Analogy:* Like walking down a mountain blindfolded to find the lowest point (valley).
3. **Introduction to FastAPI:**
   - Started exploring how to deploy ML models as Web APIs.

## Key Takeaways:
- Real-world data is complex and multivariate.
- Understanding the math (Calculus) behind Gradient Descent is crucial for optimizing models.

---
